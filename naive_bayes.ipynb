{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiutfyn/CWyK48q2gujbCb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronakraj00/lab_ml/blob/main/naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqBiF3wxhEOx"
      },
      "outputs": [],
      "source": [
        "#naive bayes\n",
        "#svm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "\n",
        "def accuracy_score(y_true, y_pred):\n",
        "\n",
        "\t\"\"\"\tscore = (y_true - y_pred) / len(y_true) \"\"\"\n",
        "\n",
        "\treturn round(float(sum(y_pred == y_true))/float(len(y_true)) * 100 ,2)\n",
        "\n",
        "def pre_processing(df):\n",
        "\n",
        "\t\"\"\" partioning data into features and target \"\"\"\n",
        "\n",
        "\tX = df.drop([df.columns[-1]], axis = 1)\n",
        "\ty = df[df.columns[-1]]\n",
        "\n",
        "\treturn X, y\n",
        "\n",
        "\n",
        "\n",
        "class  NaiveBayes:\n",
        "\n",
        "\t\"\"\"\n",
        "\t\tBayes Theorem:\n",
        "\t\t\t\t\t\t\t\t\t\tLikelihood * Class prior probability\n",
        "\t\t\t\tPosterior Probability = -------------------------------------\n",
        "\t\t\t\t\t\t\t\t\t\t\tPredictor prior probability\n",
        "\n",
        "\t\t\t\t\t\t\t  \t\t\t P(x|c) * p(c)\n",
        "\t\t\t\t\t\t\t   P(c|x) = ------------------\n",
        "\t\t\t\t\t\t\t\t\t\t\t  P(x)\n",
        "\t\"\"\"\n",
        "\n",
        "\tdef __init__(self):\n",
        "\n",
        "\t\t\"\"\"\n",
        "\t\t\tAttributes:\n",
        "\t\t\t\tlikelihoods: Likelihood of each feature per class\n",
        "\t\t\t\tclass_priors: Prior probabilities of classes\n",
        "\t\t\t\tpred_priors: Prior probabilities of features\n",
        "\t\t\t\tfeatures: All features of dataset\n",
        "\n",
        "\t\t\"\"\"\n",
        "\t\tself.features = list\n",
        "\t\tself.likelihoods = {}\n",
        "\t\tself.class_priors = {}\n",
        "\t\tself.pred_priors = {}\n",
        "\n",
        "\t\tself.X_train = np.array\n",
        "\t\tself.y_train = np.array\n",
        "\t\tself.train_size = int\n",
        "\t\tself.num_feats = int\n",
        "\n",
        "\tdef fit(self, X, y):\n",
        "\n",
        "\t\tself.features = list(X.columns)\n",
        "\t\tself.X_train = X\n",
        "\t\tself.y_train = y\n",
        "\t\tself.train_size = X.shape[0]\n",
        "\t\tself.num_feats = X.shape[1]\n",
        "\n",
        "\t\tfor feature in self.features:\n",
        "\t\t\tself.likelihoods[feature] = {}\n",
        "\t\t\tself.pred_priors[feature] = {}\n",
        "\n",
        "\t\t\tfor feat_val in np.unique(self.X_train[feature]):\n",
        "\t\t\t\tself.pred_priors[feature].update({feat_val: 0})\n",
        "\n",
        "\t\t\t\tfor outcome in np.unique(self.y_train):\n",
        "\t\t\t\t\tself.likelihoods[feature].update({feat_val+'_'+outcome:0})\n",
        "\t\t\t\t\tself.class_priors.update({outcome: 0})\n",
        "\n",
        "\t\tself._calc_class_prior()\n",
        "\t\tself._calc_likelihoods()\n",
        "\t\tself._calc_predictor_prior()\n",
        "\n",
        "\tdef _calc_class_prior(self):\n",
        "\n",
        "\t\t\"\"\" P(c) - Prior Class Probability \"\"\"\n",
        "\n",
        "\t\tfor outcome in np.unique(self.y_train):\n",
        "\t\t\toutcome_count = sum(self.y_train == outcome)\n",
        "\t\t\tself.class_priors[outcome] = outcome_count / self.train_size\n",
        "\n",
        "\tdef _calc_likelihoods(self):\n",
        "\n",
        "\t\t\"\"\" P(x|c) - Likelihood \"\"\"\n",
        "\n",
        "\t\tfor feature in self.features:\n",
        "\n",
        "\t\t\tfor outcome in np.unique(self.y_train):\n",
        "\t\t\t\toutcome_count = sum(self.y_train == outcome)\n",
        "\t\t\t\tfeat_likelihood = self.X_train[feature][self.y_train[self.y_train == outcome].index.values.tolist()].value_counts().to_dict()\n",
        "\n",
        "\t\t\t\tfor feat_val, count in feat_likelihood.items():\n",
        "\t\t\t\t\tself.likelihoods[feature][feat_val + '_' + outcome] = count/outcome_count\n",
        "\n",
        "\n",
        "\tdef _calc_predictor_prior(self):\n",
        "\n",
        "\t\t\"\"\" P(x) - Evidence \"\"\"\n",
        "\n",
        "\t\tfor feature in self.features:\n",
        "\t\t\tfeat_vals = self.X_train[feature].value_counts().to_dict()\n",
        "\n",
        "\t\t\tfor feat_val, count in feat_vals.items():\n",
        "\t\t\t\tself.pred_priors[feature][feat_val] = count/self.train_size\n",
        "\n",
        "\n",
        "\tdef predict(self, X):\n",
        "\n",
        "\t\t\"\"\" Calculates Posterior probability P(c|x) \"\"\"\n",
        "\n",
        "\t\tresults = []\n",
        "\t\tX = np.array(X)\n",
        "\n",
        "\t\tfor query in X:\n",
        "\t\t\tprobs_outcome = {}\n",
        "\t\t\tfor outcome in np.unique(self.y_train):\n",
        "\t\t\t\tprior = self.class_priors[outcome]\n",
        "\t\t\t\tlikelihood = 1\n",
        "\t\t\t\tevidence = 1\n",
        "\n",
        "\t\t\t\tfor feat, feat_val in zip(self.features, query):\n",
        "\t\t\t\t\tlikelihood *= self.likelihoods[feat][feat_val + '_' + outcome]\n",
        "\t\t\t\t\tevidence *= self.pred_priors[feat][feat_val]\n",
        "\n",
        "\t\t\t\tposterior = (likelihood * prior) / (evidence)\n",
        "\n",
        "\t\t\t\tprobs_outcome[outcome] = posterior\n",
        "\n",
        "\t\t\tresult = max(probs_outcome, key = lambda x: probs_outcome[x])\n",
        "\t\t\tresults.append(result)\n",
        "\n",
        "\t\treturn np.array(results)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\t#Weather Dataset\n",
        "\tprint(\"\\nWeather Dataset:\")\n",
        "\n",
        "\tdf = pd.read_table(\"../Data/weather.txt\")\n",
        "\t#print(df)\n",
        "\n",
        "\t#Split fearures and target\n",
        "\tX,y  = pre_processing(df)\n",
        "\n",
        "\tnb_clf = NaiveBayes()\n",
        "\tnb_clf.fit(X, y)\n",
        "\n",
        "\tprint(\"Train Accuracy: {}\".format(accuracy_score(y, nb_clf.predict(X))))\n",
        "\n",
        "\t#Query 1:\n",
        "\tquery = np.array([['Rainy','Mild', 'Normal', 't']])\n",
        "\tprint(\"Query 1:- {} ---> {}\".format(query, nb_clf.predict(query)))\n",
        "\n",
        "\t#Query 2:\n",
        "\tquery = np.array([['Overcast','Cool', 'Normal', 't']])\n",
        "\tprint(\"Query 2:- {} ---> {}\".format(query, nb_clf.predict(query)))\n",
        "\n",
        "\t#Query 3:\n",
        "\tquery = np.array([['Sunny','Hot', 'High', 't']])\n",
        "\tprint(\"Query 3:- {} ---> {}\".format(query, nb_clf.predict(query)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "7UZIPKivX3dW",
        "outputId": "292bfd7e-af11-49eb-b56d-fa7802f88115"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Weather Dataset:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../Data/weather.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-73df7182f690>\u001b[0m in \u001b[0;36m<cell line: 142>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nWeather Dataset:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Data/weather.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;31m#print(df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1403\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/weather.txt'"
          ]
        }
      ]
    }
  ]
}